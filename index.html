<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <meta name="keywords" content="HaiWu, Hai Wu, Hai Wu xmu, Hai Wu, Xiamen University, 吴海, 厦大, 厦门大学, PCL, Hailanyi,Computer,Vision,Machine,Learning,Detection,3D,Autonomous,Driving">
    <meta name="msvalidate.01" content="F525E5178C5E4AD612E361B2FA525A2E" />
    <link href="css.css" rel="stylesheet" type="text/css">
    <title>Hai Wu's Homepage (PCL)</title>
    <link rel="icon" href="image/icon.png">
  </head>
<body>
    <div class="container">

	<table border="0" id="table1" width="820">
		<tbody>
			<tr>
				<td width="210">
					<p align="center"><font face="Arial"><img border="0" src="image/wh.png" width="210" height="210"></font></p>
				</td>
				<td width="0">
					<p><font face="Arial" size="4"><a href="https://scholar.google.com/citations?user=OV7Yt14AAAAJ&hl=en"><font color="#66ccff"><b> Google Scholar</b> </font></a> </font></p>
					<p><font face="Arial" size="6"><b>&nbsp;Hai Wu <span lang="zh-cn">吴海</span></b></font></p>
					<p><font face="Arial" size="4"><a href="https://github.com/hailanyi"><font color="#66ccff"><b>GitHub Projects</b></font></a></font></p>
<!--					<p><font face="Arial" size="4">wuhai@stu.xmu.edu.cn</font></p>-->
				</td>
			</tr>
		</tbody>
	</table>


<p><font face="Arial" size="4">I am currently a assistant researcher at PCL, Shenzhen, China. I received my PhD from Xiamen University in December 2024.
	My research interests focus on computer vision and machine learning, particularly in exploring machine learning for autonomous systems. This includes 3D scene understanding,
	object detection, and other topics.
</font></p>

<p>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
<span class="style8"><strong><font face="Arial" color="#66ccff">
    <i class="fa fa-envelope" aria-hidden="true"></i> wuhai@stu.xmu.edu.cn
</font></strong>
</span>&nbsp;&nbsp;
<span class="style8"><strong><font face="Arial" color="#66ccff">
    <i class="fa fa-envelope" aria-hidden="true"></i> wuh05@pcl.ac.cn
</font></strong>
	<br></font></strong></span>
   </p>


<h2 id="news"><font face="Arial" size="4" color="#66ccff"><i class="fa fa-window-restore"></i> News</font></h2>

<ul>
  <li><font face="Arial" size="3">[2025/03] One paper accepted by CVPR 2025.</font></li>
  <li><font face="Arial" size="3">[2025/01] Two papers accepted by AAAI 2025.</font></li>
  <li><font face="Arial" size="3">[2024/07] One paper accepted by ECCV 2024.</font></li>
  <li><font face="Arial" size="3">[2024/03] Two papers accepted by CVPR 2024.</font></li>
  <li><font face="Arial" size="3">[2023/10] One paper accepted by AAAI 2024.</font></li>
  <li><font face="Arial" size="3">[2023/10] One paper accepted by ICCV 2023.</font></li>
  <li><font face="Arial" size="3">[2023/05] One paper accepted by CVPR 2023.</font></li>
  <li><font face="Arial" size="3">[2023/06] We release the <a href="https://github.com/hailanyi/VirConv">VirConv codebase</a>, which can achieve SOTA results on KITTI detection dataset.</font></li>
  <li><font face="Arial" size="3">[2023/05] Our approach VirConv-S ranks 1st on KITTI 3D/BEV/2D object detection benchmark</a>. Please refer to our paper <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Virtual_Sparse_Convolution_for_Multimodal_3D_Object_Detection_CVPR_2023_paper.pdf">VirConv</a> for more details.</font></li>
<!--  <li><font face="Arial" size="3">[2022/09] Our approach VirConvTrack ranks 1st on KITTI object tracking benchmark.</font></li>-->
<!--  <li><font face="Arial" size="3">[2022/09] One paper accepted by AAAI 2023.</font></li>-->
  <!-- <li><font face="Arial" size="3">[2022/08] One paper accepted by IEEE TGRS.</font></li> !-->
</ul>



<h2 id="Publications"><font face="Arial" size="4" color="#66ccff"><i class="fa fa-file-powerpoint"></i> Publications</font></h2>

<table border="0" style="border-width: 0px;" width="820">
    <tbody>
	        <tr>
			<td ><a href="https://hailanyi.github.io/"> <img src="image/CMD.jpg" width="210" height="110"></a></td>
<!--			<td bgcolor="#66ccff" style="border-style: none; border-width: medium;" valign="top" width="14">&nbsp;</td>-->
			<td style="border-style: none; border-width: medium;" valign="top" width="1108">
				<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">CMD: A Cross Mechanism Domain Adaptation Dataset for 3D Object Detection</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
					<font color="#000000" face="Arial" size="2"> Jinhao Deng, Wei Ye, <b>Hai Wu</b>, Qiming Xia, Xun Huang, Xin Li, Jin Fang, Wei Li, Chenglu Wen, Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
					<font face="Arial" size="2">ECCV. 2024</font><br>
				<font face="Arial" size="2">
				<a href="https://fq.pkwyx.com/default/https/www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07443.pdf"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;<b><a href="https://github.com/im-djh/CMD"><font color="#808080" face="Arial" size="2">code</font></a></b>
			</td>
			</tr>
			<tr>
			<td ><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Xia_HINTED_Hard_Instance_Enhanced_Detector_with_Mixed-Density_Feature_Fusion_for_CVPR_2024_paper.pdf"> <img src="image/HINTED.jpg" width="210" height="110"></a></td>
			<td style="border-style: none; border-width: medium;" valign="top" width="1108">
				<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">HINTED: Hard Instance Enhanced Detector with Mixed-Density Feature Fusion for Sparsely-Supervised 3D Object Detection</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
					<font color="#000000" face="Arial" size="2"> Qiming Xia, Wei Ye, <b>Hai Wu</b>, Shijia Zhao, Leyuan Xing, Xun Huang, Jinhao Deng, Xin Li, Chenglu Wen, Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
					<font face="Arial" size="2">CVPR. 2024</font><br>
				<font face="Arial" size="2">
				<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Xia_HINTED_Hard_Instance_Enhanced_Detector_with_Mixed-Density_Feature_Fusion_for_CVPR_2024_paper.pdf"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;<b><a href="https://github.com/xmuqimingxia/HINTED"><font color="#808080" face="Arial" size="2">code</font></a></b>
			</td>
			</tr>
    		<tr>
				<td > <a href="https://arxiv.org/pdf/2404.16493"><img src="image/cpd.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Commonsense Prototype for Outdoor Unsupervised 3D Object Detection</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
						<font color="#000000" face="Arial" size="2"><b>Hai Wu</b>, Shijia Zhao, Xun Huang, Chenglu Wen, Xin Li, and Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">CVPR. 2024</font><br>
					<font face="Arial" size="2">
					<a href="https://arxiv.org/pdf/2404.16493"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;<b><a href="https://github.com/hailanyi/CPD"><font color="#808080" face="Arial" size="2">code</font></a></b>
				</td>
			</tr>
    		<tr>
				<td > <a href="https://arxiv.org/pdf/2402.18493"><img src="image/SunshinetoRainstorm.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Sunshine to Rainstorm: Cross-Weather Knowledge Distillation for Robust 3D Object Detection</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
						<font color="#000000" face="Arial" size="2">Xun Huang*, <b>Hai Wu*</b>, Xin Li, Xiaoliang Fan, Chenglu Wen, and Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">AAAI. 2024</font><br>
					<font face="Arial" size="2">
					<a href="https://arxiv.org/pdf/2402.18493"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;<b><a href="https://github.com/ylwhxht/SRKD-DRET"><font color="#808080" face="Arial" size="2">code</font></a></b>
				</td>
			</tr>
    		<tr>
				<td ><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Virtual_Sparse_Convolution_for_Multimodal_3D_Object_Detection_CVPR_2023_paper.pdf"> <img src="image/virconv.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Virtual Sparse Convolution for Multimodal 3D Object Detection</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
						<font color="#000000" face="Arial" size="2"><b>Hai Wu</b>, Chenglu Wen, Shaoshuai Shi, Xin Li, Chenglu Wen, and Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">CVPR. 2023</font><br>
					<font face="Arial" size="2">
					<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Virtual_Sparse_Convolution_for_Multimodal_3D_Object_Detection_CVPR_2023_paper.pdf"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;<b><a href="https://github.com/hailanyi/VirConv"><font color="#808080" face="Arial" size="2">code</font></a></b>
				</td>
			</tr>
        	<tr>
				<td > <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.pdf"><img src="image/COIN.jpg" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">CoIn: Contrastive Instance Feature Mining for Outdoor 3D Object Detection with Very Limited Annotations</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
						<font color="#000000" face="Arial" size="2">Qiming Xia, Jinhao Deng, Chenglu Wen, <b>Hai Wu</b>, Shaoshuai Shi, Xin Li, and Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">ICCV. 2023</font><br>
					<font face="Arial" size="2">
					<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.pdf"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;<b><a href="https://github.com/xmuqimingxia/CoIn"><font color="#808080" face="Arial" size="2">code</font></a></b>
				</td>
			</tr>
            <tr>
				<td > <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25380/25152"><img src="image/TED.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Transformation-equivariant 3D object detection for autonomous driving</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
                        <font color="#000000" face="Arial" size="2"><b>Hai Wu</b>, Chenglu Wen, Wei Li, Xin Li, Ruigang Yang, Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">AAAI. 2023</font><br>
					<font face="Arial" size="2">
					<a href="https://ojs.aaai.org/index.php/AAAI/article/view/25380/25152"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;<b><a href="https://github.com/hailanyi/TED"><font color="#808080" face="Arial" size="2">code</font></a></b>
				</td>
			</tr>
            <tr>
				<td > <a href="https://ieeexplore.ieee.org/abstract/document/9870747"><img src="image/casa.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">CasA: A cascade attention network for 3-D object detection from LiDAR point clouds</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
                        <font color="#000000" face="Arial" size="2"><b>Hai Wu</b>, Jinhao Deng, Chenglu Wen, Xin Li, Cheng Wang, and Jonathan Li</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">IEEE TGRS. 2022</font><br>
					<font face="Arial" size="2">
					<a href="https://ieeexplore.ieee.org/abstract/document/9870747"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;<b><a href="https://github.com/hailanyi/CasA"><font color="#808080" face="Arial" size="2">code</font></a></b>
				</td>
			</tr>
            <tr>
				<td > <a href="https://ieeexplore.ieee.org/abstract/document/10091688"><img src="image/SemanticFlow.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">SemanticFlow: Semantic Segmentation of Sequential LiDAR Point Clouds From Sparse Frame Annotations</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
                        <font color="#000000" face="Arial" size="2">Junhao Zhao, Weijie Huang, <b>Hai Wu</b>, Chenglu Wen,Yulan Guo, and Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">IEEE TGRS. 2023</font><br>
					<font face="Arial" size="2">
					<a href="https://ieeexplore.ieee.org/abstract/document/10091688"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;
				</td>
			</tr>
            <tr>
				<td ><a href="https://link.springer.com/content/pdf/10.1007/s41095-021-0260-6.pdf"><font color="#808080"> <img src="image/BLNet.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">BLNet: Bidirectional learning network for point clouds</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
                        <font color="#000000" face="Arial" size="2">Wenkai Han, <b>Hai Wu</b>, Chenglu Wen, Cheng Wang, Xin Li</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">Computational Visual Media. 2022</font><br>
					<font face="Arial" size="2">
					<a href="https://link.springer.com/content/pdf/10.1007/s41095-021-0260-6.pdf"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;
				</td>
			</tr>
            <tr>
				<td > <a href="https://web.archive.org/web/20210813010629id_/https://www.ijcai.org/proceedings/2021/0161.pdf"><img src="image/Tracklet.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Tracklet Proposal Network for Multi-Object Tracking on Point Clouds</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
                        <font color="#000000" face="Arial" size="2"> <b>Hai Wu</b>, Qing Li, Chenglu Wen, Xin Li, Xiaoliang Fan, Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">IJCAI. 2021</font><br>
					<font face="Arial" size="2">
					<a href="https://web.archive.org/web/20210813010629id_/https://www.ijcai.org/proceedings/2021/0161.pdf"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;
				</td>
			</tr>
            <tr>
				<td ><a href="https://ieeexplore.ieee.org/abstract/document/9352500"> <img src="image/tracking.gif" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">3D multi-object tracking in point clouds based on prediction confidence-guided data association</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
                        <font color="#000000" face="Arial" size="2"> <b>Hai Wu</b>, Wenkai Han, Chenglu Wen, Xin Li, Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">IEEE TITS. 2021</font><br>
					<font face="Arial" size="2">
					<a href="https://ieeexplore.ieee.org/abstract/document/9352500"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;
				</td>
			</tr>
            <tr>
				<td > <a href="https://drive.google.com/file/d/1H0q43zfr5t2ozohzFAJs3RlHSN4-V6Y_/view"><img src="image/human_trajectory.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Indoor 3D human trajectory reconstruction using surveillance camera videos and point clouds</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
                        <font color="#000000" face="Arial" size="2">Yudi Dai, Chenglu Wen, <b>Hai Wu</b>, Yulan Guo, Longbiao Chen, Cheng Wang</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">IEEE Transactions on Circuits and Systems for Video Technology. 2021</font><br>
					<font face="Arial" size="2">
					<a href="https://drive.google.com/file/d/1H0q43zfr5t2ozohzFAJs3RlHSN4-V6Y_/view"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;
				</td>
			</tr>
            <tr>
				<td ><a href="https://www.sciencedirect.com/science/article/pii/S0924271619301947"> <img src="image/boundary.png" width="210" height="110"></a></td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Recovery of urban 3D road boundary via multi-source data</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
                        <font color="#000000" face="Arial" size="2">Chenglu Wen, Changbin You, <b>Hai Wu</b>, Cheng Wang, Xiaoliang Fan, Jonathan Li</font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">ISPRS Journal of Photogrammetry and Remote Sensing. 2019</font><br>
					<font face="Arial" size="2">
					<a href="https://www.sciencedirect.com/science/article/pii/S0924271619301947"><font color="#808080"><font color="#808080">paper</font></font></a>&nbsp;&nbsp;&nbsp;
				</td>
			</tr>
    <tbody>
</table>



<h2 id="activities"><font face="Arial" size="4" color="#66ccff"><i class="fa fa-male"></i> Activities</font></h2>


	  <p style="margin-top:0px;margin-bottom:-10px;"><font face="Arial" size="3"><b>Reviewer:</b></font></p><br />
      <p>  <font face="Arial" size="3"> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<br />
	  Conference on Neural Information Processing Systems (NeurIPS) <br />
	  International Conference on Learning Representation (ICLR) <br />
      AAAI Conference on Artificial Intelligence (AAAI)<br />
      IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)<br />
      IEEE Transactions on Image Processing (TIP)<br />
      IEEE Transactions on Geoscience and Remote Sensing (TGRS)<br />
	  IEEE Transactions on Intelligent Transportation Systems (TITS)<br />

<!--	  <p style="margin-top:0px;margin-bottom:-10px;"><font face="Arial" size="3"><b>Presentation:</b></font></p><br />-->
<!--      <p>  <font face="Arial" size="3"> Commonsense Prototype for Outdoor Unsupervised 3D Object Detection, CVPR, USA, Seattle, 2024<br />-->
<!--      <p>  <font face="Arial" size="3"> Virtual Sparse Convolution for Multimodal 3D Object Detection, CVPR, Vancouver, Canada, 2023<br />-->
<!--      Transformation-equivariant 3D object detection for autonomous driving, AAAI, Washington, D.C., USA, 2023<br />-->
<!--	  Tracklet Proposal Network for Multi-Object Tracking on Point Clouds, Japan, 2021</font></p>-->

	  <p style="margin-top:0px;margin-bottom:-10px;"><b><font face="Arial" size="3">Internship:</font></b></p><br />
	  <p> <font face="Arial" size="3"> Research Intern, March 2022 - June 2022, Inceptio technology, Shanghai, China.<br /> Advised by Ruigang Yang.</font></p>


<h2 id="awards"><font face="Arial" size="4" color="#66ccff"><i class="fa fa-trophy"></i> Academic Competition and Awards</font></h2>

  <p><font face="Arial" size="3">
   National scholarship, 2023<br />
   Second prize in data processing at LiDAR Conference, 2023<br />
   VirConv-S ranks No.1(car) on the KITTI 2D, 3D and BEV detection leaderboard, 11/2022 <br />
   VirConvTrack ranks No.1(car) on the KITTI tracking leaderboard, 11/2022 <br />
   CasTrack ranks No.1(car) on the KITTI tracking leaderboard, 09/2022 <br />
   TED ranks No.1(car) on the KITTI 3D detection leaderboard, 05/2022 <br />
   PC-TCNN ranks No.1(car) on the KITTI tracking leaderboard, 01/2021 <br />
   Excellent student scholarship, 2021
</font><br /></p>



<table border="0" id="table2" width="700">
<tbody>
	<tr>
		<td width="220">
			<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=ilqA5GNJCkpARTKQ5PEMa4KL1M4wI92q3Q9UEoKSc-Q&w=210&t=tt&ct=00c5ff"></script>
<!--			<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=00c5ff&w=a&t=tt&d=ilqA5GNJCkpARTKQ5PEMa4KL1M4wI92q3Q9UEoKSc-Q&ct=00c5ff&co=ffffff'></script>-->
		</td>
		<td width="0">
			<p><font face="Arial" size="4" color="#66ccff">The journey is long and arduous </font></p>
			<p><font face="Arial" size="5">&nbsp;<b><span lang="zh-cn">路漫漫其修远兮，吾将上下而求索</span></b></font></p>
            <p><font face="Arial" size="4" color="#66ccff"> I will explore it with unyielding spirit</font></p>
		</td>
	</tr>
</tbody>
</table>


 &emsp; © Hai Wu, 2023 - 2025

</div>
</body>
</html>
