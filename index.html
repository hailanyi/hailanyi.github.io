<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hai Wu's Homepage</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        :root {
            --primary-color: #66ccff;
            --secondary-color: #333;
            --accent-color: #333;
            --text-color: #333;
            --light-text: #66ccff;
            --card-bg: rgba(235, 235, 255, 0.8);
            --gradient-start: #FFFFFF;
            --gradient-end: #99CCFF;
            --sidebar-width: 280px; /* 控制左侧卡片宽度 */
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        body {
            background: linear-gradient(135deg, var(--gradient-start), var(--gradient-end));
            color: var(--text-color);
            min-height: 100vh;
            padding: 20px;
            position: relative;
            overflow-x: hidden;
        }

        /* 粒子背景 */
        #particles-js {
            position: absolute;
            width: 100%;
            height: 100%;
            top: 0;
            left: 0;
            z-index: -1;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            display: grid;
            grid-template-columns: var(--sidebar-width) 1fr; /* 使用变量控制布局 */
            gap: 30px;
        }

        /* 左侧卡片样式 */
        .profile-card {
            /*background: var(--card-bg);*/
            /*backdrop-filter: blur(10px);*/
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            height: 100vh;
            position: sticky;
            top: 20px;
            width: 100%; /* 宽度由父元素控制 */
                        display: flex;
            flex-direction: column;
            justify-content: center;
        }

        .profile-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 35px rgba(0, 0, 0, 0.2);
        }

        /* 宽度控制面板 */
        .width-control {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background: white;
            padding: 15px;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
            z-index: 100;
        }

        .width-control h3 {
            margin-bottom: 10px;
            font-size: 16px;
            color: var(--primary-color);
        }

        .width-control input {
            width: 100%;
        }

        .width-value {
            text-align: center;
            margin-top: 5px;
            font-weight: bold;
        }
        .profile-img {
            width: 160px;
            height: 160px;
            border-radius: 50%;
            object-fit: cover;
            margin: 0 auto 20px;
            display: block;
            border: 5px solid white;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }

        .profile-ball {
            text-align: justify;
            width: 300px;
            height: 300px;
            top: 30px;
            border-radius: 50%;
            object-fit: cover;
            margin: 0 auto 0px;
            display: block;
            transition: transform 0.3s ease;
        }

        .profile-img:hover {
            transform: scale(1.05);
        }

        .profile-name {
            text-align: center;
            font-size: 24px;
            margin-bottom: 10px;
            color: var(--primary-color);
        }

        .profile-title {
            text-align: center;
            font-size: 14px;
            margin-bottom: 20px;
            color: var(--secondary-color);
        }

        .profile-info {
            font-size: 14px;
            text-align: justify;
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-top: 10px;
        }


        .social-links {
            font-size: 14px;
            text-align: justify;
            display: flex;
            justify-content: center;
            gap: 15px;
            margin: 0 auto 20px;
            margin-top: 10px;
        }


        .social-log {
            font-size: 14px;
            text-align: center;
        }
        .social-links a {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 36px;
            height: 36px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            text-decoration: none;
            transition: all 0.3s ease;
        }

        .social-links a:hover {
            background: var(--secondary-color);
            transform: translateY(-3px);
        }

        /* Content section */
        .content {
            display: flex;
            flex-direction: column;
            gap: 30px;
        }

        .section {
            background: var(--card-bg);
            backdrop-filter: blur(10px);
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
            opacity: 0;
            transform: translateY(20px);
            animation: fadeIn 0.6s forwards;
        }

        .section:hover {
            transform: translateY(-5px);
        }

        .section-title {
            font-size: 18px;
            margin-bottom: 20px;
            color: var(--primary-color);
            display: flex;
            align-items: center;
        }

        .section-title i {
            margin-right: 10px;
        }

        /* News section */
        .news-item {
            font-size: 14px;
            margin-bottom: 15px;
            padding-bottom: 15px;
            border-bottom: 1px solid rgba(0, 0, 0, 0.1);
        }

        .news-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .news-date {
            color: var(--primary-color);
            font-weight: 600;
            margin-bottom: 5px;
        }

        /* Publications */
        .publications-container {
            display: grid;
            gap: 20px;
        }

        .publication-item {
            display: grid;
            grid-template-columns: 400px 1fr;
            gap: 20px;
            padding: 20px;
            border-radius: 15px;
            background: rgba(255, 255, 255, 0.6);
            transition: all 0.3s ease;
        }

        .publication-item:hover {
            background: rgba(255, 255, 255, 0.8);
            transform: translateX(5px);
        }

        .publication-img {
            width: 100%;
            height: 100px;
            object-fit: cover;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .publication-content h3 {
            font-size: 14px;
            margin-bottom: 10px;
            color: var(--secondary-color);
        }

        .publication-authors {
            font-size: 12px;
            margin-bottom: 10px;
            color: #555;
        }

        .publication-venue {
            font-size: 14px;
            font-weight: 600;
            margin-bottom: 10px;
            color: var(--primary-color);
        }

        .publication-links a {
            display: inline-block;
            margin-right: 15px;
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s ease;
        }

        .publication-links a:hover {
            color: var(--secondary-color);
            transform: translateY(-2px);
        }

        .more-btn {
            display: block;
            margin: 20px auto 0;
            padding: 12px 30px;
            background: var(--primary-color);
            color: white;
            border: none;
            border-radius: 30px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .more-btn:hover {
            background: var(--secondary-color);
            transform: translateY(-3px);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.2);
        }

        .hidden {
            display: none;
        }

        /* Activities & Awards */
        .activities-list, .awards-list {
            list-style-type: none;
        }

        .activities-list li, .awards-list li {
            margin-bottom: 5px;
            padding-left: 25px;
            position: relative;
        }

        .activities-list li:before, .awards-list li:before {
            content: "•";
            color: var(--secondary-color);
            font-weight: bold;
            position: absolute;
            left: 0;
        }

        /* Footer */
        footer {
            text-align: center;
            margin-top: 50px;
            padding: 20px;
            color: var(--light-text);
            opacity: 0.8;
        }

        .quote {
            font-style: italic;
            margin-bottom: 15px;
            font-size: 14px;
            color: var(--secondary-color);
        }

        /* Animations */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .delay-1 {
            animation-delay: 0.2s;
        }

        .delay-2 {
            animation-delay: 0.4s;
        }

        .delay-3 {
            animation-delay: 0.6s;
        }

        /* Responsive design */
        @media (max-width: 1100px) {
            .container {
                grid-template-columns: 1fr;
            }

            .profile-card {
                position: static;
                margin-bottom: 30px;
            }
        }

        @media (max-width: 768px) {
            .publication-item {
                grid-template-columns: 1fr;
            }

            .publication-img {
                height: 180px;
            }
        }
    </style>
</head>
<body>
    <div id="particles-js"></div>

    <div class="container">
        <!-- Left Profile Card -->
        <div class="profile-card">
            <img src="image/wh.png" alt="Hai Wu" class="profile-img">
            <h1 class="profile-name">Hai Wu (吴海)</h1>


             <div class="social-log">
            <p > <i class="fas fa-user"></i> Assistant Researcher </p>
            <p > <i class="fas fa-building"></i> Pengcheng Laboratory </p>
            <p > <i class="fas fa-map-marker-alt"> </i> Shenzhen, China </p>
            <p > <i class="fas fa-graduation-cap"> </i> Xiamen University </p>

            </div>

            <div class="profile-info">
                <p> I am currently an assistant researcher at PCL, Shenzhen, China. I received my PhD from Xiamen University in December 2024.
	My research interests focus on computer vision and machine learning, particularly in exploring machine learning for autonomous systems. This includes 3D scene understanding,
	object detection, and other topics. </p>

            </div>

            <div class="social-links">
                <a href="https://scholar.google.com/citations?user=OV7Yt14AAAAJ&hl=en" title="Google Scholar"><i class="fas fa-graduation-cap"></i></a>
                <a href="https://github.com/hailanyi" title="GitHub"><i class="fab fa-github"></i></a>
                <a href="mailto: wuhai@stu.xmu.edu.cn" title="wuhai@stu.xmu.edu.cn"><i class="fas fa-envelope"></i></a>
                <a href="mailto: wuh05@pcl.ac.cn" title="wuh05@pcl.ac.cn"><i class="fas fa-envelope"></i></a>
            </div>

            <div class="social-log">

<a href='https://clustrmaps.com/site/1c0b2'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=220&t=n&d=ilqA5GNJCkpARTKQ5PEMa4KL1M4wI92q3Q9UEoKSc-Q&co=98d5ff'/></a>
            <p class="social-log">© Hai Wu, 2023 - 2025</p>
            </div>


        </div>

        <!-- Right Content -->
        <div class="content">
            <!-- News Section -->

            <section class="section">
                <h2 class="section-title"><i class="fas fa-newspaper"></i> News</h2>

                <ul class="awards-list">
                <li> <span class="news-date">[2025/08]</span> One paper accepted by <span class="highlight">IEEE TPAMI</span>. </li>

                <li> <span class="news-date">[2025/07]</span> Two papers accepted by <span class="highlight">ICCV 2025</span>.</li>

                <li>  <span class="news-date">[2025/03]</span> One paper accepted by <span class="highlight">CVPR 2025</span>.</li>

                <li>  <span class="news-date">[2025/01]</span> Two papers accepted by <span class="highlight">AAAI 2025</span>.</li>

                <li>  <span class="news-date">[2024/07]</span> One paper accepted by <span class="highlight">ECCV 2024</span>.</li>

                <li>   <span class="news-date">[2024/03]</span> Two papers accepted by <span class="highlight">CVPR 2024</span>.</li>
                <li>   <span class="news-date">[2023/10]</span>  One paper accepted by <span class="highlight">ICCV 2023</span>.</li>
                <li>   <span class="news-date">[2023/05]</span> One paper accepted by <span class="highlight">CVPR 2023</span>.</li>

                </ul>






            </section>

            <!-- Publications Section -->
            <section class="section delay-1">
                <h2 class="section-title"><i class="fas fa-file-alt"></i> Selected Publications</h2>

                <div class="publications-container">
                    <!-- Publication 1 -->

                      <div class="publication-item ">
                        <div class="publication-content">
                            <h3>Unsupervised 3D Object Detection by Commonsense Clue</h3>
                            <p class="publication-authors"><b>Hai Wu</b>, Shijia Zhao, Xun Huang, Qiming Xia, Chenglu Wen, Li Jiang, Xin Li, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">TPAMI 2025</a>
                                <a href="https://ieeexplore.ieee.org/abstract/document/11124320/"><i class="fas fa-file-pdf"></i> Paper</a>
                            </div>
                        </div>
                        <img src="image/cpd2.png" alt="Publication" class="publication-img">
                      </div>

                     <div class="publication-item ">
                        <div class="publication-content">
                            <h3>Commonsense Prototype for Outdoor Unsupervised 3D Object Detection</h3>
                            <p class="publication-authors"><b>Hai Wu</b>, Shijia Zhao, Xun Huang, Chenglu Wen, Xin Li, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">CVPR 2024</a>
                                <a href="https://arxiv.org/pdf/2404.16493"><i class="fas fa-file-pdf"></i> Paper</a>
                                <a href="https://github.com/hailanyi/CPD"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                        <img src="image/cpd.png" alt="Publication" class="publication-img">
                    </div>

                     <div class="publication-item">
                        <div class="publication-content">
                            <h3>Virtual Sparse Convolution for Multimodal 3D Object Detection</h3>
                            <p class="publication-authors"><b>Hai Wu</b>, Chenglu Wen, Shaoshuai Shi, Xin Li, Chenglu Wen, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">CVPR 2023</a>
                                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Virtual_Sparse_Convolution_for_Multimodal_3D_Object_Detection_CVPR_2023_paper.pdf"><i class="fas fa-file-pdf"></i> Paper</a>
                                <a href="https://github.com/hailanyi/VirConv"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                        <img src="image/virconv.png" alt="Publication" class="publication-img">
                    </div>

                    <div class="publication-item ">
                        <div class="publication-content">
                            <h3>Transformation-equivariant 3D object detection for autonomous driving</h3>
                            <p class="publication-authors"><b>Hai Wu</b>, Chenglu Wen, Wei Li, Xin Li, Ruigang Yang, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">AAAI 2023</a>
                                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25380/25152"><i class="fas fa-file-pdf"></i> Paper</a>
                                <a href="https://github.com/hailanyi/TED"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                        <img src="image/TED.png" alt="Publication" class="publication-img">
                    </div>

                    <div class="publication-item ">
                        <div class="publication-content">
                            <h3>CasA: A cascade attention network for 3-D object detection from LiDAR point clouds</h3>
                            <p class="publication-authors"><b>Hai Wu</b>, Jinhao Deng, Chenglu Wen, Xin Li, Cheng Wang, Jonathan Li</p>
                            <div class="publication-links">
                                <a class="publication-venue">IEEE TGRS 2022</a>
                                <a href="https://ieeexplore.ieee.org/abstract/document/9870747"><i class="fas fa-file-pdf"></i> Paper</a>
                                <a href="https://github.com/hailanyi/CasA"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                        <img src="image/casa.png" alt="Publication" class="publication-img">
                    </div>


                    <!-- Hidden publications -->




                    <div class="publication-item hidden">

                        <div class="publication-content">
                            <h3>SP3D: Boosting Sparsely-Supervised 3D Object Detection via Accurate Cross-Modal Semantic Prompts</h3>
                            <p class="publication-authors">Shijia Zhao, Qiming Xia, Xusheng Guo, Pufan Zou, Maoji Zheng, <b>Hai Wu</b>, Chenglu Wen, Cheng Wang</p>

                            <div class="publication-links">
                                <a class="publication-venue">CVPR 2025</a>
                                <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_SP3D_Boosting_Sparsely-Supervised_3D_Object_Detection_via_Accurate_Cross-Modal_Semantic_CVPR_2025_paper.pdf"><i class="fas fa-file-pdf"></i> Paper</a>
<!--                                <a href="#"><i class="fas fa-code"></i> Code</a>-->
                            </div>
                        </div>
                        <img src="image/SP3D.png" alt="Publication" class="publication-img">
                    </div>

                    <!-- Publication 2 -->
                    <div class="publication-item hidden">

                        <div class="publication-content">
                            <h3>L4dr: Lidar-4dradar fusion for weather-robust 3d object detection</h3>
                            <p class="publication-authors">Xun Huang, Ziyu Xu, <b>Hai Wu</b>, Jinlong Wang, Qiming Xia, Yan Xia, Jonathan Li, Kyle Gao, Chenglu Wen, Cheng Wang</p>

                            <div class="publication-links">
                                <a class="publication-venue">AAAI 2025</a>
                                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/32397/34552"><i class="fas fa-file-pdf"></i> Paper</a>
                                <a href="https://github.com/ylwhxht/L4DR"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                        <img src="image/L4dr.png" alt="Publication" class="publication-img">
                    </div>

                    <!-- Publication 3 -->
                    <div class="publication-item hidden">

                        <div class="publication-content">
                            <h3>Seg2Box: 3D Object Detection by Point-Wise Semantics Supervision</h3>
                            <p class="publication-authors">Maoji Zheng, Ziyu Xu, Qiming Xia, <b>Hai Wu</b>, Chenglu Wen, Cheng Wang</p>

                            <div class="publication-links">
                                <a class="publication-venue">AAAI 2025</a>
                                <a href="https://ojs.aaai.org/index.php/AAAI/article/download/33150/35305"><i class="fas fa-file-pdf"></i> Paper</a>
<!--                                <a href="#"><i class="fas fa-code"></i> Code</a>-->
                            </div>
                        </div>
                         <img src="image/Seg2Box.png" alt="Publication" class="publication-img">
                    </div>



                    <div class="publication-item hidden">

                        <div class="publication-content">
                            <h3>CMD: A Cross Mechanism Domain Adaptation Dataset for 3D Object Detection</h3>
                            <p class="publication-authors">Jinhao Deng, Wei Ye, <b>Hai Wu</b>, Qiming Xia, Xun Huang, Xin Li, Jin Fang, Wei Li, Chenglu Wen, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">ECCV 2024</a>
                                <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07443.pdf"><i class="fas fa-file-pdf"></i> Paper</a>
                                <a href="https://github.com/im-djh/CMD"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                        <img src="image/CMD.jpg" alt="Publication" class="publication-img">
                    </div>

                     <div class="publication-item hidden">
                        <div class="publication-content">
                            <h3>HINTED: Hard Instance Enhanced Detector with Mixed-Density Feature Fusion for Sparsely-Supervised 3D Object Detection</h3>
                            <p class="publication-authors">Qiming Xia, Wei Ye, <b>Hai Wu</b>, Shijia Zhao, Leyuan Xing, Xun Huang, Jinhao Deng, Xin Li, Chenglu Wen, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">CVPR 2024</a>
                                <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Xia_HINTED_Hard_Instance_Enhanced_Detector_with_Mixed-Density_Feature_Fusion_for_CVPR_2024_paper.pdf"><i class="fas fa-file-pdf"></i> Paper</a>
                                <a href="https://github.com/xmuqimingxia/HINTED"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                        <img src="image/HINTED.jpg" alt="Publication" class="publication-img">
                    </div>



                    <div class="publication-item hidden">
                        <div class="publication-content">
                            <h3>Sunshine to Rainstorm: Cross-Weather Knowledge Distillation for Robust 3D Object Detection</h3>
                            <p class="publication-authors">Xun Huang*, <b>Hai Wu*</b>, Xin Li, Xiaoliang Fan, Chenglu Wen, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">AAAI 2024</a>
                                <a href="https://arxiv.org/pdf/2402.18493"><i class="fas fa-file-pdf"></i> Paper</a>
                                <a href="https://github.com/ylwhxht/SRKD-DRET"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                        <img src="image/SunshinetoRainstorm.png" alt="Publication" class="publication-img">
                    </div>

                    <div class="publication-item hidden">
                        <div class="publication-content">
                            <h3>CoIn: Contrastive Instance Feature Mining for Outdoor 3D Object Detection with Very Limited Annotations</h3>
                            <p class="publication-authors">Qiming Xia, Jinhao Deng, Chenglu Wen, <b>Hai Wu</b>, Shaoshuai Shi, Xin Li, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">ICCV 2023</a>
                                <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.pdf"><i class="fas fa-file-pdf"></i> Paper</a>
                                <a href="https://github.com/xmuqimingxia/CoIn"><i class="fas fa-code"></i> Code</a>
                            </div>
                        </div>
                        <img src="image/COIN.jpg" alt="Publication" class="publication-img">
                    </div>


                    <div class="publication-item hidden">
                        <div class="publication-content">
                            <h3>SemanticFlow: Semantic Segmentation of Sequential LiDAR Point Clouds From Sparse Frame Annotations</h3>
                            <p class="publication-authors">Junhao Zhao, Weijie Huang, <b>Hai Wu</b>, Chenglu Wen, Yulan Guo, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">IEEE TGRS 2023</a>
                                <a href="https://ieeexplore.ieee.org/abstract/document/10091688"><i class="fas fa-file-pdf"></i> Paper</a>
                            </div>
                        </div>
                        <img src="image/SemanticFlow.png" alt="Publication" class="publication-img">
                    </div>

                    <div class="publication-item hidden">
                        <div class="publication-content">
                            <h3>BLNet: Bidirectional learning network for point clouds</h3>
                            <p class="publication-authors">Wenkai Han, <b>Hai Wu</b>, Chenglu Wen, Cheng Wang, Xin Li</p>
                            <div class="publication-links">
                                <a class="publication-venue">Computational Visual Media 2022</a>
                                <a href="https://link.springer.com/content/pdf/10.1007/s41095-021-0260-6.pdf"><i class="fas fa-file-pdf"></i> Paper</a>
                            </div>
                        </div>
                        <img src="image/BLNet.png" alt="Publication" class="publication-img">
                    </div>

                    <div class="publication-item hidden">
                        <div class="publication-content">
                            <h3>Tracklet Proposal Network for Multi-Object Tracking on Point Clouds</h3>
                            <p class="publication-authors"><b>Hai Wu</b>, Qing Li, Chenglu Wen, Xin Li, Xiaoliang Fan, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">IJCAI 2021</a>
                                <a href="https://web.archive.org/web/20210813010629id_/https://www.ijcai.org/proceedings/2021/0161.pdf"><i class="fas fa-file-pdf"></i> Paper</a>
                            </div>
                        </div>
                        <img src="image/Tracklet.png" alt="Publication" class="publication-img">
                    </div>

                    <div class="publication-item hidden">
                        <div class="publication-content">
                            <h3>3D multi-object tracking in point clouds based on prediction confidence-guided data association</h3>
                            <p class="publication-authors"><b>Hai Wu</b>, Wenkai Han, Chenglu Wen, Xin Li, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">IEEE TITS 2021</a>
                                <a href="https://ieeexplore.ieee.org/abstract/document/9352500"><i class="fas fa-file-pdf"></i> Paper</a>
                            </div>
                        </div>
                        <img src="image/tracking.gif" alt="Publication" class="publication-img">
                    </div>

                    <div class="publication-item hidden">
                        <div class="publication-content">
                            <h3>Indoor 3D human trajectory reconstruction using surveillance camera videos and point clouds</h3>
                            <p class="publication-authors">Yudi Dai, Chenglu Wen, <b>Hai Wu</b>, Yulan Guo, Longbiao Chen, Cheng Wang</p>
                            <div class="publication-links">
                                <a class="publication-venue">IEEE TCSVT 2021</a>
                                <a href="https://drive.google.com/file/d/1H0q43zfr5t2ozohzFAJs3RlHSN4-V6Y_/view"><i class="fas fa-file-pdf"></i> Paper</a>
                            </div>
                        </div>
                        <img src="image/human_trajectory.png" alt="Publication" class="publication-img">
                    </div>

                    <div class="publication-item hidden">
                        <div class="publication-content">
                            <h3>Recovery of urban 3D road boundary via multi-source data</h3>
                            <p class="publication-authors">Chenglu Wen, Changbin You, <b>Hai Wu</b>, Cheng Wang, Xiaoliang Fan, Jonathan Li</p>
                            <div class="publication-links">
                                <a class="publication-venue">ISPRS Journal of Photogrammetry and Remote Sensing 2019</a>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0924271619301947"><i class="fas fa-file-pdf"></i> Paper</a>
                            </div>
                        </div>
                        <img src="image/boundary.png" alt="Publication" class="publication-img">
                    </div>


                <button class="more-btn" id="more-publications">Show All Publications</button>
            </section>

            <!-- Activities Section -->
            <section class="section delay-2">
                <h2 class="section-title"><i class="fas fa-tasks"></i> Activities</h2>

                <h3>Reviewer:</h3>
                <ul class="activities-list">
                    <li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
                    <li>Conference on Neural Information Processing Systems (NeurIPS)</li>
                    <li>International Conference on Learning Representation (ICLR)</li>
                    <li>AAAI Conference on Artificial Intelligence (AAAI)</li>
                    <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
                    <li>IEEE Transactions on Image Processing (TIP)</li>
                    <li>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</li>
                    <li>IEEE Transactions on Intelligent Transportation Systems (TITS)</li>
                </ul>

                <h3>Internship:</h3>
                <ul class="activities-list">
                    <li>Research Intern, March 2022 - June 2022, Inceptio technology, Shanghai, China. Advised by Ruigang Yang.</li>
                </ul>
            </section>

            <!-- Awards Section -->
            <section class="section delay-3">
                <h2 class="section-title"><i class="fas fa-trophy"></i> Academic Competition and Awards</h2>

                <ul class="awards-list">
                    <li>National scholarship, 2023</li>
                    <li>Second prize in data processing at LiDAR Conference, 2023</li>
                    <li>VirConv-S ranks No.1(car) on the KITTI 2D, 3D and BEV detection leaderboard, 11/2022</li>
                    <li>VirConvTrack ranks No.1(car) on the KITTI tracking leaderboard, 11/2022</li>
                    <li>CasTrack ranks No.1(car) on the KITTI tracking leaderboard, 09/2022</li>
                    <li>TED ranks No.1(car) on the KITTI 3D detection leaderboard, 05/2022</li>
                    <li>PC-TCNN ranks No.1(car) on the KITTI tracking leaderboard, 01/2021</li>
                    <li>Excellent student scholarship, 2021</li>
                </ul>
            </section>



        </div>
    </div>

    <footer>
        <p class="quote">"The journey is long and arduous, I will explore it with unyielding spirit"</p>
        <p class="quote">路漫漫其修远兮，吾将上下而求索</p>
    </footer>

    <script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
    <script>
        // Particles.js configuration
        document.addEventListener('DOMContentLoaded', function() {
            particlesJS('particles-js', {
                particles: {
                    number: { value: 120, density: { enable: true, value_area: 800 } },
                    color: { value: "#ffffff" },
                    shape: { type: "circle" },
                    opacity: { value: 0.5, random: true },
                    size: { value: 3, random: true },
                    line_linked: {
                        enable: true,
                        distance: 150,
                        color: "#ffffff",
                        opacity: 0.4,
                        width: 1.2
                    },
                    move: {
                        enable: true,
                        speed: 2,
                        direction: "none",
                        random: true,
                        out_mode: "out",
                        bounce: false
                    }
                },
                interactivity: {
                    detect_on: "canvas",
                    events: {
                        onhover: { enable: true, mode: "grab" },
                        onclick: { enable: true, mode: "push" },
                        resize: true
                    }
                },
                retina_detect: true
            });

            // Show more publications functionality
            const moreBtn = document.getElementById('more-publications');
            const hiddenPublications = document.querySelectorAll('.publication-item.hidden');
            let showingAll = false;

            moreBtn.addEventListener('click', function() {
                hiddenPublications.forEach(item => {
                    item.classList.toggle('hidden');
                });

                if (showingAll) {
                    moreBtn.textContent = 'Show All Publications';
                    window.scrollBy(0, -200); // Smooth scroll up a bit
                } else {
                    moreBtn.textContent = 'Show Selected Publications';
                }

                showingAll = !showingAll;
            });

            // Add animation delays for sections
            const sections = document.querySelectorAll('.section');
            sections.forEach((section, index) => {
                section.style.animationDelay = `${index * 0.2}s`;
            });
        });
    </script>
</body>
</html>
